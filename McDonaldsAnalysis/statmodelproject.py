# -*- coding: utf-8 -*-
"""StatModelProject.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CZBSlMx5kBE9Pg2HtYyezxy82dHQo-98
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.metrics import roc_curve, roc_auc_score
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import confusion_matrix, accuracy_score
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import LeaveOneOut
from sklearn.metrics import mean_squared_error, r2_score
import statsmodels.api as sm
from matplotlib.colors import LinearSegmentedColormap

#Pre-processing and Cleaning
mcdonalds = pd.read_csv('https://raw.githubusercontent.com/yousabg/PythonProjects/main/McDonaldsAnalysis/menu.csv')
wendys = pd.read_csv('https://raw.githubusercontent.com/yousabg/PythonProjects/main/McDonaldsAnalysis/wendys-menu.csv')
burger_king = pd.read_csv('https://raw.githubusercontent.com/yousabg/PythonProjects/main/McDonaldsAnalysis/burger-king-menu.csv')
chickfila = pd.read_csv('https://raw.githubusercontent.com/yousabg/PythonProjects/main/McDonaldsAnalysis/chick-fil-a-nutrition.csv')

#One hot encoding mcdonalds to get ready for classifying as breakfast
one_hot_encoded = pd.get_dummies(mcdonalds['Category'], prefix='category')
mcdonalds = pd.concat([mcdonalds, one_hot_encoded], axis=1)
numeric_columns = [col for col in mcdonalds.select_dtypes(include=[np.number]).columns if '% Daily Value' not in col and col != 'Calories from Fat']

#Making all the column names the same to prepare for same modeling
wendys = wendys.rename(columns={
    'Fat (g)': 'Total Fat',
    'Sat Fat (g)': 'Saturated Fat',
    'Trans Fat (g)': 'Trans Fat',
    'Cholesterol (mg)': 'Cholesterol',
    'Sodium (mg)': 'Sodium',
    'Total Carb (g)': 'Carbohydrates',
    'Dietary Fiber (g)': 'Dietary Fiber',
    'Sugars (g)': 'Sugars',
    'Protein (g)': 'Protein'
})
wendys = wendys.drop('Weight Watchers', axis=1)

burger_king = burger_king.rename(columns={
    'Fat (g)': 'Total Fat',
    'Saturated Fat (g)': 'Saturated Fat',
    'Trans Fat (g)': 'Trans Fat',
    'Cholesterol (mg)': 'Cholesterol',
    'Sodium (mg)': 'Sodium',
    'Total Carb (g)': 'Carbohydrates',
    'Dietary Fiber (g)': 'Dietary Fiber',
    'Sugars (g)': 'Sugars',
    'Protein (g)': 'Protein'
})
burger_king = burger_king.drop('Weight Watchers', axis=1)

chickfila['Breakfast'] = False
chickfila.loc[:32, 'Breakfast'] = True
chickfila.loc[33]
chickfila = chickfila.rename(columns={
    'Fat (G)': 'Total Fat',
    'Sat. Fat (G)': 'Saturated Fat',
    'Trans Fat (G)': 'Trans Fat',
    'Cholesterol (MG)': 'Cholesterol',
    'Sodium (MG)': 'Sodium',
    'Carbohydrates (G)': 'Carbohydrates',
    'Fiber (G)': 'Dietary Fiber',
    'Sugar (G)': 'Sugars',
    'Protein (G)': 'Protein'
})
chickfila = chickfila.rename(columns={'Menu': 'Item'})

#Combining the datasets for later analyzing
columns_to_keep = ['Item', 'Calories', 'Total Fat', 'Saturated Fat', 'Trans Fat', 'Cholesterol',
                   'Sodium', 'Carbohydrates', 'Dietary Fiber', 'Sugars', 'Protein']
df1 = mcdonalds[columns_to_keep]
df2 = wendys[columns_to_keep]
df3 = burger_king[columns_to_keep]
df4 = chickfila[columns_to_keep]
foods = pd.concat([df1, df2, df3, df4], ignore_index=True)
foods = foods[foods['Protein'] < 100]
foods.reset_index(drop=True, inplace=True)

"""DATA DICTIONARY:

Item - Name of the food item

Category (McDonalds) - The category that the food item belongs to. In the non-mcdonalds dataset, this may just be a boolean for whether or not it is breakfast.

Calories - Amount of calories in the food item for that serving

Total Fat - Amount of total fat in the food item for that serving

Saturated Fat - Amount of saturated fat in the food item for that serving

Trans Fat - Amount of trans fat in the food item for that serving

Cholesterol - Amount of cholesterol in the food item for that serving

Sodium - Amount of sodium in the food item for that serving

Carbohydrates - Amount of carbohydrates in the food item for that serving

Dietary Fiber - Amount of dietary fiber in the food item for that serving

Sugars - Amount of sugar in the food item for that serving

Protein - Amount of protein in the fodo item for that serving

"""

#Visualization 1: Histogram of Categories in Mcdoanlds
plt.figure(figsize=(8, 6))
sns.countplot(x='Category', data=mcdonalds, palette='viridis')
plt.title('Distribution of Categories in Mcdonalds Menu')
plt.xlabel('Category')
plt.ylabel('Count')
plt.xticks(rotation = 45)
plt.show()

#Visualization 2: Average nutritional values by category in Mcdonalds
avg_values = mcdonalds.groupby('Category')[numeric_columns].mean().reset_index()

plt.figure(figsize=(12, 12))

for component in numeric_columns:
    plt.plot(avg_values['Category'], avg_values[component], label=component)

plt.title('Average Nutritional Values by Category')
plt.xlabel('Category')
plt.ylabel('Average Value')
plt.xticks(avg_values['Category'])
plt.legend(loc='upper right', bbox_to_anchor=(1.3, 1))
plt.grid(True)
plt.show()

#Visluzation 3: Coorelation Heatmap
foods_c = foods.select_dtypes(include=[np.number])
correlation_matrix = foods_c.corr()
plt.figure(figsize=(8, 6))
sns.heatmap(correlation_matrix, annot=True, cmap='bwr', fmt='.2f', linewidths=.5)

#Visulization 4: Regplot of protein and every other nutritioinal value
fig, axs = plt.subplots(3, 3, figsize=(15, 10))

sns.regplot(x='Calories', y='Protein', data=foods, ax=axs[0, 0])
sns.regplot(x='Total Fat', y='Protein', data=foods, ax=axs[0, 1])
sns.regplot(x='Saturated Fat', y='Protein', data=foods, ax=axs[1, 0])
sns.regplot(x='Carbohydrates', y='Protein', data=foods, ax=axs[1, 1])
sns.regplot(x='Dietary Fiber', y='Protein', data=foods, ax=axs[2, 0])
sns.regplot(x='Sugars', y='Protein', data=foods, ax=axs[2, 1])
sns.regplot(x='Trans Fat', y='Protein', data=foods, ax=axs[2, 2])
sns.regplot(x='Sodium', y='Protein', data=foods, ax=axs[0, 2])
sns.regplot(x='Cholesterol', y='Protein', data=foods, ax=axs[1, 2])



plt.tight_layout()
plt.show()

#PREDICTION 1
#PROBLEM: Can we predict if an item should be classified as breakfast or not based on the other nutritional values?
#PREDICTORS: 'Calories','Total Fat','Saturated Fat','Trans Fat','Cholesterol','Sodium','Carbohydrates','Dietary Fiber','Sugars','Protein'
#TARGET: mcdonalds['category_breakfast] (the one hot encoded for breakfast). this was visualized in visualization 1

X = mcdonalds[numeric_columns]
y = mcdonalds['category_Breakfast']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

model = LogisticRegression(random_state=42)
model.fit(X_train, y_train)

y_pred = model.predict(X_test)

cm = confusion_matrix(y_test, y_pred)

#These are Mcdonalds colors lol
colors = ["#FFC300", "#FF5733"]
mcd_cmap = LinearSegmentedColormap.from_list("mcd_cmap", colors, N=256)

plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap=mcd_cmap, xticklabels=['Not Breakfast', 'Breakfast'], yticklabels=['Not Breakfast', 'Breakfast'], annot_kws={"size": 25})
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy:.2f}")
#The accuracy score is 96%
#The model is actually very good, since it only made 1 false negative and 1 false positive mistake

X = mcdonalds[numeric_columns]
y_true = mcdonalds['category_Breakfast']

y_probs = model.predict_proba(X)[:, 1]

fpr, tpr, thresholds = roc_curve(y_true, y_probs)
roc_auc = roc_auc_score(y_true, y_probs)

plt.figure()
plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve' % roc_auc)
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic')
plt.legend(loc="lower right")
plt.show()
#The ROC curve for this model is also very good

#Now, I wanna see if this mcdonalds-trained model could work on similar restaraunts!
def try_model(df, colors, y_true = None):
  X = df[numeric_columns]
  y_pred = model.predict(X)
  y_true = (df['Category'] == 'Breakfast') if y_true is None else y_true

  accuracy = accuracy_score(y_true, y_pred)
  print(f"Accuracy: {accuracy:.2f}")

  cm = confusion_matrix(y_true, y_pred)

  cmap = LinearSegmentedColormap.from_list("cmap", colors, N=256)

  plt.figure(figsize=(10, 7))
  sns.heatmap(cm, annot=True, fmt='d', cmap=cmap,
            xticklabels=['Not Breakfast', 'Breakfast'],
            yticklabels=['Not Breakfast', 'Breakfast'],
            annot_kws={"size": 25})
  plt.xlabel('Predicted')
  plt.ylabel('Actual')
  plt.show()

  mask = y_pred != y_true
  incorrect_predictions = df[mask]

  try:
    print(incorrect_predictions[['Item', 'Category']])
  except KeyError as e:
    return incorrect_predictions

colors = ["#ffcccc", "#ff0000"]
try_model(wendys, colors)
#This was also really good, somehow even a bit better than the mcdonalds one. It only got 1 sandwhich wrong as listed below.

colors = ["#0046AD", "#D62300"]
try_model(burger_king, colors)
#This was not as good, but lets see if we can tune it!!!

X = burger_king[numeric_columns]
y_true = (burger_king['Category'] == 'Breakfast')

y_probs = model.predict_proba(X)[:, 1]

fpr, tpr, thresholds = roc_curve(y_true, y_probs)
roc_auc = roc_auc_score(y_true, y_probs)

plt.figure()
plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic')
plt.legend(loc="lower right")
plt.show()

optimal_idx = np.argmax(tpr - fpr)
optimal_threshold = thresholds[optimal_idx]
y_pred_optimal = (y_probs >= optimal_threshold).astype(int)
accuracy_optimal = accuracy_score(y_true, y_pred_optimal)
cm_optimal = confusion_matrix(y_true, y_pred_optimal)
plt.figure(figsize=(10, 7))
colors = ["#0046AD", "#D62300"]
bk_cmap = LinearSegmentedColormap.from_list("bk_cmap", colors, N=256)

sns.heatmap(cm_optimal, annot=True, fmt='d', cmap=bk_cmap,
            xticklabels=['Not Breakfast', 'Breakfast'],
            yticklabels=['Not Breakfast', 'Breakfast'],
            annot_kws={"size": 25})
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()
mask = y_pred_optimal != y_true
incorrect_predictions = burger_king[mask]

print("Incorrectly predicted rows:")
print(incorrect_predictions[['Item', 'Category']])
#This is a bit better

colors = ["#FFA3A3", "#C00000"]
y_true = chickfila['Breakfast']
ip = try_model(chickfila, colors, y_true)
print("Incorrect Predictions")
print(ip[['Item', 'Breakfast']])
#this wasnt good lets try to tune it again

X = chickfila[numeric_columns]
y_true = chickfila['Breakfast']

y_probs = model.predict_proba(X)[:, 1]

fpr, tpr, thresholds = roc_curve(y_true, y_probs)
roc_auc = roc_auc_score(y_true, y_probs)

plt.figure()
plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic')
plt.legend(loc="lower right")
plt.show()

optimal_idx = np.argmax(tpr - fpr)
optimal_threshold = thresholds[optimal_idx]
y_pred_optimal = (y_probs >= optimal_threshold).astype(int)
accuracy_optimal = accuracy_score(y_true, y_pred_optimal)
cm_optimal = confusion_matrix(y_true, y_pred_optimal)
colors = ["#FFA3A3", "#C00000"]
cfa_cmap = LinearSegmentedColormap.from_list("cfa_cmap", colors, N=256)

plt.figure(figsize=(10, 7))
sns.heatmap(cm_optimal, annot=True, fmt='d', cmap=cfa_cmap,
            xticklabels=['Not Breakfast', 'Breakfast'],
            yticklabels=['Not Breakfast', 'Breakfast'],
            annot_kws={"size": 25})
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()
mask = y_pred_optimal != y_true
incorrect_predictions = chickfila[mask]

print("Incorrectly predicted rows:")
print(incorrect_predictions[['Item', 'Breakfast']])
#this was still pretty bad, probably because of systematic differences between mcdonalds and chickfila

coefficients = model.coef_[0]
features = numeric_columns

feature_importance = pd.DataFrame(coefficients, index=numeric_columns, columns=['Coefficient'])

sorted_features = feature_importance.sort_values(by='Coefficient', ascending=True)

plt.figure(figsize=(10, 8))
plt.barh(sorted_features.index, sorted_features['Coefficient'], color='skyblue')
plt.xlabel('Coefficients')
plt.title('Most Important Features')
plt.show()

equation = "y = "
for feature, coeff in zip(features, coefficients):
    equation += f"({coeff:.2f} * {feature}) + "
equation += f"{model.intercept_[0]:.2f}"

print("Model Equation:")
print(equation)
#The most useful features here seem to be dietary fiber, protein, and saturated fat.

#PREDICTION 2
#Problem: I wanna see if I can predict how much protein is in a fast food item based on the other nutritional factors
#Visualization 2 3 and 4 show the distribution and coorelation of protein in the food items
X = foods.drop(columns=['Item', 'Protein', 'Sodium', 'Cholesterol']) #Removed Sodium and Cholesterol since they have no significance (feature selection)
y = foods['Protein']
loo = LeaveOneOut()
y_true, y_pred = [], []

for train_index, test_index in loo.split(X):
    X_train, X_test = X.iloc[train_index], X.iloc[test_index]
    y_train, y_test = y[train_index], y[test_index]

    model = LinearRegression()
    model.fit(X_train, y_train)
    prediction = model.predict(X_test)

    y_true.append(y_test.iloc[0])
    y_pred.append(prediction[0])

mse = mean_squared_error(y_true, y_pred)
r2 = r2_score(y_true, y_pred)
print(f"Mean Squared Error: {mse:.3f}")
print(f"R^2 Score: {r2:.3f}")
model = LinearRegression()
model.fit(X, y)

coefficients = pd.DataFrame({
    'Feature': X.columns,
    'Coefficient': model.coef_
}).sort_values(by='Coefficient', ascending=False)

print(coefficients)


plt.figure(figsize=(12, 8))
plt.barh(coefficients['Feature'], coefficients['Coefficient'], color='red')
plt.xlabel('Coefficient Value', fontsize=12, color='darkred')
plt.ylabel('Features', fontsize=12, color='darkred')

for index, value in enumerate(coefficients['Coefficient']):
    plt.text(value, index, f'{value:.2f}', va='center', ha='right' if value < 0 else 'left', fontweight='bold', color='darkred')

plt.gca().invert_yaxis()
plt.tight_layout()
plt.show()
#Model is also doing really well with a R^2 of 0.967. The MSE of 6.289 is not bad considering the range of proteins and the unit (grams)
#The most useful predictors seem to be total fat, carbohydrates, and trans fat.

"""Tuning and Validation:
Cross Validating results: I used LOOCV on the linear regression model. I used it because I only had around 600 points, which I think was computationally enough to be handled. Also, I wanted a very precise measurement to fast food items specifically, so loocv was likley to give me that.

Feature Importance: I created such a visulization for both my logistic regression and linear regression models.

Feature Selection: In my linear regression model, I used backward selection to remove sodium and chloesterol from my predictors. My model told me they had very high p-values, which means they did not have a huge significance on the target. I removed these until all the predictors had p-values lower than 0.5

Tuning: I tuned both the burger king and chickfila models that were predicted based on the mcdonalds model. I wanted to see if I could get the best of both worlds (simplicity and specificity) by choosing an optimal threshold through a ROC curve. It worked for the burger king model and made it a lot better, but the chickfila one was still pretty bad.


"""